# -*- coding: utf-8 -*-

# Keras as interface -> configurations in configuration file of Keras
# Backend = Tensorflow | Dimension = 'tf'
from tensorflow.keras import backend as K
import math

# Configuration class with initializations
class Config:

	def __init__(self):

		# Execution mode program -> command line input with '-v'
		self.verbose = True

		# Basic CNN -> feature extraction -> VGG16
		self.network = 'vgg'

		# Configurations for data augmentation
		self.use_horizontal_flips = False # Horizontal flip
		self.use_vertical_flips = False	  # Vertical flip
		self.rot_90 = False		  # Rotation 90Â°

		# Scales for anchor boxes (height x with) -> scale (128 x 128), (256 x 256), (512 x 512)
		self.anchor_box_scales = [64, 128, 256]

		# Ratio for anchor boxes (height:width) -> decreasement
		self.anchor_box_ratios = [[1, 1], [1./math.sqrt(2), 2./math.sqrt(2)], [2./math.sqrt(2), 1./math.sqrt(2)]]

		# Minimum size image set to px = 300 -> after resizing
		self.im_size = 300

		# Standardization pixel values of input data -> subtraction channel mean value
		self.img_channel_mean = [103.939, 116.779, 123.68]
		self.img_scaling_factor = 1.0

		# Number of region proposals (ROIs) in image to be processed -> ROI pooling layer
		# Image contains 300 region proposals
		self.num_rois = 4

		# RPN stride: depends on base network configuration -> subsampling ratio r = 16 
		self.rpn_stride = 16

		self.balanced_classes = False

		# Scaling of standard distribution -> standardization
		self.std_scaling = 4.0
		self.classifier_regr_std = [8.0, 8.0, 4.0, 4.0]

		# Thresholds for overlaps of anchor boxes & ground truth boxes
		self.rpn_min_overlap = 0.3 # IOU <= 0.3 (negative)
		self.rpn_max_overlap = 0.7 # IOU >= 0.7 (positive)

		# Thresholds for overlaps of region proposals & ground truth boxes
		self.classifier_min_overlap = 0.1 # IOU >= 0.1 & IOU <= 0.5 (background)
		self.classifier_max_overlap = 0.5 # IOU >= 0.5 (positiv)

		# Placeholder for the class mapping, automatically generated by the parser
		self.class_mapping = None

		# Location of trained output weights for VGG16 network (path)
		# self.model_path = '/home/benan/Detektion/Model/model_frcnn_vgg.hdf5'
		self.model_path = None

